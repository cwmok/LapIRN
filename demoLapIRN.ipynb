{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demoLapIRN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idhamari/LapIRN/blob/master/demoLapIRN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPmRrG-6Dkq4"
      },
      "source": [
        "# 3D Medical Image Registration with DNN\n",
        "\n",
        "Using Laplacian Pyramid Deep Learning Networks (LAPIRN)\n",
        "\n",
        "This is a demo notebook for a github repository [LabIRN](https://github.com/cwmok/LapIRN/blob/master/Code/Train_LapIRN_disp.py). The original code author is [Tony Chi Wing MOK](https://cwmok.github.io/). If you have questions please open issue in the original repository. \n",
        "\n",
        "the paper can be downloaded from [here](https://arxiv.org/abs/2006.16148).\n",
        "\n",
        "\n",
        "The dataset used is from [learn2reg challenge](https://learn2reg.grand-challenge.org/Datasets). It can be downloaded from ()\n",
        "\n",
        "Notes:\n",
        "  - some bugs are fixed.\n",
        "\n",
        "Todos:\n",
        "  - use tensorboard to draw training and testing curves \n",
        "  - improve the reading/writing procedures\n",
        "  - remove redundant code\n",
        "\n",
        "\n",
        "**This notebook is controbuted by:** Ibraheem Al-Dhamari\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIvFGWlcGwla"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W_x8y2tkiU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c124e824-45a7-4d2f-9fd9-864f7dbae49f"
      },
      "source": [
        "# you can also work with your google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "firstRun = 1 \n",
        "\n",
        "if firstRun:\n",
        "    !pip3 install -U scikit-learn\n",
        "    !pip3 install simpleitk\n",
        "    !pip3 install tensorflow==1.14 tensorflow-gpu==1.14 keras==2.3.1\n",
        "    !pip3 install nibabel tqdm\n",
        "\n",
        "    #clone the updated code\n",
        "    !mkdir LapIRN_org\n",
        "    !git clone https://github.com/idhamari/LapIRN.git LapIRN_org/LapIRN\n",
        "    print('-------------------')\n",
        "    !ls LapIRN_org/LapIRN\n",
        "    print(\"cloning repository is done!\")\n",
        "    \n",
        "    # download the dataset    \n",
        "    !mkdir LapIRN_org/datasets\n",
        "    # note use the same lines with changing the only the id\n",
        "    !curl -c /tmp/cookies \"https://drive.google.com/uc?export=download&id=17uysjRAiXMIT2QApW5kHWP1aHCi5_lPO\" > tmp.txt\n",
        "    !curl -L -b /tmp/cookies \"https://drive.google.com$(cat tmp.txt | grep -Po 'uc-download-link\" [^>]* href=\"\\K[^\"]*' | sed 's/\\&amp;/\\&/g')\" >  LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144.zip\n",
        "    !ls  LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144.zip -l --block-size=M \n",
        "    !unzip LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144.zip -d LapIRN_org/datasets \n",
        "    !ls   LapIRN_org/datasets\n",
        "    print(\"downloading dataset is done!\")\n",
        "    firstRun = 0\n",
        "  \n",
        "print(\"important note: copy or download the results if you want to save them\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.6MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n",
            "Collecting simpleitk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/6b/85df5eb3a8059b23a53a9f224476e75473f9bcc0a8583ed1a9c34619f372/SimpleITK-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 60kB/s \n",
            "\u001b[?25hInstalling collected packages: simpleitk\n",
            "Successfully installed simpleitk-2.0.2\n",
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 99kB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/67/559ca8408431c37ad3a17e859c8c291ea82f092354074baef482b98ffb7b/tensorflow_gpu-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (377.1MB)\n",
            "\u001b[K     |████████████████████████████████| 377.1MB 44kB/s \n",
            "\u001b[?25hCollecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 51.2MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 53.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.4MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 50.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (54.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "Installing collected packages: tensorflow-estimator, keras-applications, tensorboard, tensorflow, tensorflow-gpu, keras\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.3.1 keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from nibabel) (1.19.5)\n",
            "Cloning into 'LapIRN_org/LapIRN'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 54 (delta 20), reused 40 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (54/54), done.\n",
            "-------------------\n",
            "Code  Data  demoLapIRN_org.py  LICENSE.md  Model  README.md\n",
            "cloning repository is done!\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3299    0  3299    0     0  16331      0 --:--:-- --:--:-- --:--:-- 16331\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3162      0 --:--:-- --:--:-- --:--:--  3162\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  371M    0  371M    0     0  72.0M      0 --:--:--  0:00:05 --:--:-- 86.1M\n",
            "-rw-r--r-- 1 root root 372M Apr 13 13:07 LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144.zip\n",
            "Archive:  LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144.zip\n",
            "   creating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/\n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0001.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0001_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0002.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0002_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0003.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0003_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0004.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0004_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0005.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0005_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0006.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0006_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0007.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0007_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0008.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0008_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0009.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0009_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0010.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0010_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0021.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0021_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0022.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0022_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0023.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0023_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0024.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0024_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0025.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0025_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0026.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0026_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0027.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0027_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0028.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0028_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0029.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0029_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0030.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0030_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0031.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0031_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0032.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0032_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0033.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0033_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0034.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0034_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0035.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0035_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0036.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0036_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0037.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0037_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0038.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0038_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0039.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0039_seg.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0040.nii.gz  \n",
            "  inflating: LapIRN_org/datasets/L2R_Task3_AbdominalCT_160x192x144/img0040_seg.nii.gz  \n",
            "L2R_Task3_AbdominalCT_160x192x144  L2R_Task3_AbdominalCT_160x192x144.zip\n",
            "downloading dataset is done!\n",
            "important note: copy or download the results if you want to save them\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQtPocugG0eE"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZnWL1uk6xfW",
        "outputId": "55e8a4ee-4f42-44a3-b003-cfca78246895"
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "!ls  \n",
        "#os.chdir('drive/MyDrive/DNN/LapIRN_org/LapIRN/Code')\n",
        "# work_directory\n",
        "wd_path      ='/content/LapIRN_org/'\n",
        "# dataset\n",
        "dataset_path = '../../datasets/L2R_Task3_AbdominalCT_160x192x144'\n",
        "# 30 images,  image size =  192,160,256, each has its segmentation, the segmentation has 13 segmentation classes,\n",
        "\n",
        "scriptPath = wd_path + 'LapIRN/demoLapIRN_org.py'\n",
        "\n",
        "doTrain    = 1\n",
        "lvl1       = 3    \n",
        "lvl2       = 3    \n",
        "lvl3       = 200  \n",
        "checkpoint = 100\n",
        "\n",
        "!python $scriptPath $doTrain $lvl1 $lvl2 $lvl3 $checkpoint $wd_path $dataset_path\n",
        "\n",
        "\n",
        "# download the pretrained model\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LapIRN_org  sample_data  tmp.txt\n",
            "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
            "                 Setup                                        \n",
            "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /content/LapIRN_org/LapIRN/demoLapIRN_org.py:65: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/LapIRN_org/LapIRN/demoLapIRN_org.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/LapIRN_org/LapIRN/demoLapIRN_org.py:66: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2021-04-13 13:08:28.261926: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-04-13 13:08:28.266632: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-04-13 13:08:28.266897: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562bf89e8a80 executing computations on platform Host. Devices:\n",
            "2021-04-13 13:08:28.266928: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2021-04-13 13:08:28.269896: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-13 13:08:28.454489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-13 13:08:28.455210: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562bf89e8e00 executing computations on platform CUDA. Devices:\n",
            "2021-04-13 13:08:28.455239: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-04-13 13:08:28.456247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-13 13:08:28.456786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-04-13 13:08:28.484373: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-04-13 13:08:28.675533: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-04-13 13:08:28.767430: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-04-13 13:08:28.784110: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-04-13 13:08:29.011819: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-04-13 13:08:29.168312: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-04-13 13:08:29.667567: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-13 13:08:29.667755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-13 13:08:29.668418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-13 13:08:29.668924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-04-13 13:08:29.668996: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-04-13 13:08:29.670757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-13 13:08:29.670790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2021-04-13 13:08:29.670801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2021-04-13 13:08:29.670915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-13 13:08:29.671479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-13 13:08:29.671979: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-04-13 13:08:29.672023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12087 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "user arguments:  ['/content/LapIRN_org/LapIRN/demoLapIRN_org.py', '1', '3', '3', '200', '100', '/content/LapIRN_org/', '../../datasets/L2R_Task3_AbdominalCT_160x192x144']\n",
            "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
            "                 Parameters Setting                           \n",
            "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
            "['/content/LapIRN_org/LapIRN/demoLapIRN_org.py', '1', '3', '3', '200', '100', '/content/LapIRN_org/', '../../datasets/L2R_Task3_AbdominalCT_160x192x144']\n",
            "using user arguments .................\n",
            "script is running locally...........\n",
            "1.14.0\n",
            "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
            "                 Parameters Setting                           \n",
            "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
            "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
            "                 Dataset                           \n",
            "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
            "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
            "                 Train                                        \n",
            "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
            "--------------------------------------------\n",
            "        Start Training                      \n",
            "--------------------------------------------\n",
            "datapath :  ../../datasets/L2R_Task3_AbdominalCT_160x192x144\n",
            "../../datasets/L2R_Task3_AbdominalCT_160x192x144\n",
            "len(names) :  30\n",
            "imgshape:  (160, 192, 144)\n",
            "Training lvl1...\n",
            "step \"3\" -> training loss \"-285195206656.0000\" - sim_NCC \"-285195206656.000000\" - Jdet \"161.6609497070\" -smo \"79.3020\"one epoch pass\n",
            "Training lvl2...\n",
            "Loading weight for model_lvl1... ../Model/Stage/LDR_OASIS_NCC_unit_disp_add_reg_1_stagelvl1_0.pth\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "step \"3\" -> training loss \"-868437786624.0000\" - sim_NCC \"-868437786624.000000\" - Jdet \"1880.9948730469\" -smo \"307.6215\"one epoch pass\n",
            "Training lvl3...\n",
            "Loading weight for model_lvl2... ../Model/Stage/LDR_OASIS_NCC_unit_disp_add_reg_1_stagelvl2_0.pth\n",
            "step \"0\" -> training loss \"-338084593664.0000\" - sim_NCC \"-338084593664.000000\" - Jdet \"15789.7285156250\" -smo \"1270.7758\"Traceback (most recent call last):\n",
            "  File \"Train_LapIRN_disp.py\", line 418, in <module>\n",
            "    train_lvl3()\n",
            "  File \"Train_LapIRN_disp.py\", line 391, in train_lvl3\n",
            "    [loss.item(), loss_multiNCC.item(), loss_Jacobian.item(), loss_regulation.item()])\n",
            "KeyboardInterrupt\n",
            "Training Time:  37.47110366821289\n",
            "testing is disabled ! ................\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdfX-MlzG5Cf"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSdyfGPNuCeU"
      },
      "source": [
        "#run testing on testing dataset and save results "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OjoHH2uG8Gf"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWrc1W3FG-h7"
      },
      "source": [
        "#Draw results "
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}